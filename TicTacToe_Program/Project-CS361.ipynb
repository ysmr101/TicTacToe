{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb517c6",
   "metadata": {},
   "source": [
    "-**In this tutorial we will write an interactive AI, solving game problems by adversarial search.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dff708",
   "metadata": {},
   "source": [
    "**Games in AI:**  \n",
    "Game Theory is basically a branch of mathematics that is used to typical strategic interaction between different players (agents), all of which are equally rational, in a context with predefined rules (of playing or maneuvering) and outcomes. Every player or agent is a rational entity who is selfish and tries to maximize the reward to be obtained using a particular strategy. All the players abide by certain rules in order to receive a predefined playoff- a reward after a certain outcome. Hence, a GAME can be defined as a set of players, actions, strategies, and a final playoff for which all the players are competing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60a8da5",
   "metadata": {},
   "source": [
    "**Game Tree:**   \n",
    "a game tree is a graph representing all possible game states within such a game. Such games include well-known ones such as chess, checkers, Go, and tic-tac-toe. This can be used to measure the complexity of a game, as it represents all the possible ways a game can pan out. Due to the large game trees of complex games such as chess, algorithms that are designed to play this class of games will use partial game trees, which makes computation feasible on modern computers. Various methods exist to solve game trees. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611edfae",
   "metadata": {},
   "source": [
    "![SegmentLocal](game-tree1.jpg \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c5a5d",
   "metadata": {},
   "source": [
    "**Game as search:**  \n",
    "1-\tThe initial state is the state the agent begins in  \n",
    "2-\tA goal state is a state where the agent may end the search.  \n",
    "3-\tA state is a set of properties that define the current conditions of the world our agent is in.  \n",
    "&emsp;a.\tThink of this as a snapshot of the world at a given point in time  \n",
    "&emsp;b.\tThe entire set of possible states is called the state space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38fbdd",
   "metadata": {},
   "source": [
    "-An example of a game is **TicTacToe:**  \n",
    "\n",
    "Tic-tac-toe is a game for two players who take turns marking the spaces in a three-by-three grid with X or O. The player who succeeds in placing three of their marks in a horizontal, vertical, or diagonal row is the winner. It is a solved game, with a forced draw assuming best play from both players.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342a310",
   "metadata": {},
   "source": [
    "![SegmentLocal](TicTactoe.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c16b6a",
   "metadata": {},
   "source": [
    "-A player can play a perfect game of tic-tac-toe (to win or at least draw) if, each time it is their turn to play, they choose the first available move from the following list, as used in Newell and Simon's 1972 tic-tac-toe program.\n",
    "\n",
    "1-\tWin: If the player has two in a row, they can place a third to get three in a row. \n",
    "\n",
    "2-\tBlock: If the opponent has two in a row, the player must play the third themselves to block the opponent.\n",
    "\n",
    "3-\tFork: Cause a scenario where the player has two ways to win (two non-blocked lines of 2).  \n",
    "\n",
    "4-\tBlocking an opponent's fork: If there is only one possible fork for the opponent, the player should block it. Otherwise, the player should block all forks in any way that simultaneously allows them to make two in a row. Otherwise, the player should make a two in a row to force the opponent into defending, as long as it does not result in them producing a fork. For example, if \"X\" has two opposite corners and \"O\" has the center, \"O\" must not play a corner move to win. (Playing a corner move in this scenario produces a fork for \"X\" to win.) \n",
    "\n",
    "5-\tCenter: A player marks the center. (If it is the first move of the game, playing a corner move gives the second player more opportunities to make a mistake and may therefore be the better choice; however, it makes no difference between perfect players.)  \n",
    "\n",
    "6-\tOpposite corner: If the opponent is in the corner, the player plays the opposite corner.  \n",
    "\n",
    "7-\tEmpty corner: The player plays in a corner square.  \n",
    "\n",
    "8-\tEmpty side: The player plays in a middle square on any of the four sides.           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba483fd",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c74134",
   "metadata": {},
   "source": [
    "**Adversarial Search in AI:**      \n",
    "While talking about such searches in AI, adversarial search is one of the most important kinds of search. It is very prominent in gaming techniques. The use of the adversarial technique can be found in different games as in games the AI agent has been surrounded by a kind of competitive environment. The goal has been defined initially by the user and the agents compete or fight with one another in order to achieve that goal so that the win can be achieved. The adversarial search is important, and each agent must have known the strategy of the next agent this will create a competitive environment in a game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2964452d",
   "metadata": {},
   "source": [
    "**Evaluation function:**  \n",
    "An evaluation function, also known as a heuristic evaluation function or static evaluation function, is a function used by game-playing computer programs to estimate the value or goodness of a position (usually at a leaf or terminal node) in a game tree. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7b24d4",
   "metadata": {},
   "source": [
    "**There are multiple methods that uses Adversarial search, however the most common are MINIMAX and ALPHA-BETA PRUNING:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07f4814",
   "metadata": {},
   "source": [
    "**MinMax:**   \n",
    "Minimax is a kind of backtracking algorithm that is used in decision making and game theory to find the optimal move for a player, assuming that your opponent also plays optimally. It is widely used in two player turn-based games such as Tic-Tac-Toe, Backgammon, Mancala, Chess, etc.\n",
    "In Minimax the two players are called maximizer and minimizer. The maximizer tries to get the highest score possible while the minimizer tries to do the opposite and get the lowest score possible.\n",
    "Every board state has a value associated with it. In a given state if the maximizer has upper hand, then, the score of the board will tend to be some positive value. If the minimizer has the upper hand in that board state, then it will tend to be some negative value. The values of the board are calculated by some heuristics which are unique for every type of game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dbbf08",
   "metadata": {},
   "source": [
    "**A graph that explains how Minimax works:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636adaef",
   "metadata": {},
   "source": [
    "![SegmentLocal](minmax.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e1490e",
   "metadata": {},
   "source": [
    "**Example for Minimax in tic-tac-toe:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c368c",
   "metadata": {},
   "source": [
    "![SegmentLocal](tic-tac-toe-Minimax.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ffb13",
   "metadata": {},
   "source": [
    "**MinMax's Pseudocode:**  \n",
    "function  minimax( node, depth, maximizingPlayer ) is   \n",
    "&emsp;    if depth = 0 or node is a terminal node then  \n",
    "&emsp;&emsp;       return the heuristic value of node  \n",
    "&emsp;    if maximizingPlayer then  \n",
    "&emsp;&emsp;    value := −∞  \n",
    "&emsp;&emsp;    for each child of node do  \n",
    "&emsp;&emsp;&emsp;    value := max( value, minimax( child, depth − 1, FALSE ) )  \n",
    "&emsp;&emsp;   return value  \n",
    "&emsp;    else (* minimizing player *)  \n",
    "&emsp;&emsp;  value := +∞  \n",
    "&emsp;&emsp;  for each child of node do  \n",
    "&emsp;&emsp;&emsp;   value := min( value, minimax( child, depth − 1, TRUE ) )  \n",
    "&emsp;&emsp;  return value \n",
    "_________\n",
    "\n",
    "Time complexity = O(b^m)  \n",
    "Space complexity = O(bm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee0cc0",
   "metadata": {},
   "source": [
    "**Alpha-Beta Pruning:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7266e61",
   "metadata": {},
   "source": [
    "**Alpha-Beta Pruning** is not actually a new algorithm, rather an optimization technique for minimax algorithm. It reduces the computation time by a huge factor. This allows us to search much faster and even go into deeper levels in the game tree. It cuts off branches in the game tree which need not be searched because there already exists a better move available. It is called Alpha-Beta pruning because it passes 2 extra parameters in the minimax function, namely alpsha and beta.\n",
    "Let’s define the parameters alpha and beta.   \n",
    "Alpha is the best value that the maximizer currently can guarantee at that level or above.   \n",
    "Beta is the best value that the minimizer currently can guarantee at that level or above.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0813be7",
   "metadata": {},
   "source": [
    "**Example for Alpha-Beta Pruning in tic-tac-toe:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65eb441",
   "metadata": {},
   "source": [
    "![SegmentLocal](alphabetapruning-Tic-tac-toe.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64273204",
   "metadata": {},
   "source": [
    "**Alpha-Beta Pruning's Pseudocode:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d721cd",
   "metadata": {},
   "source": [
    "function minimax(node, depth, isMaximizingPlayer, alpha, beta):  \n",
    "&emsp;    if node is a leaf node :  \n",
    "&emsp;&emsp;       return value of the node  \n",
    "&emsp;   if isMaximizingPlayer :  \n",
    "&emsp;&emsp;      bestVal = -INFINITY   \n",
    "&emsp;&emsp;      for each child node :  \n",
    "&emsp;&emsp;&emsp;         value = minimax(node, depth+1, false, alpha, beta)  \n",
    "&emsp;&emsp;&emsp;        bestVal = max( bestVal, value)   \n",
    "&emsp;&emsp;&emsp;      alpha = max( alpha, bestVal)  \n",
    "&emsp;&emsp;&emsp;      if beta <= alpha:  \n",
    "&emsp;&emsp;&emsp;        break  \n",
    "&emsp;&emsp;   return bestVal  \n",
    "\n",
    "    else :\n",
    "        bestVal = +INFINITY \n",
    "        for each child node :\n",
    "            value = minimax(node, depth+1, true, alpha, beta)\n",
    "            bestVal = min( bestVal, value) \n",
    "            beta = min( beta, bestVal)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return bestVal \n",
    "_________\n",
    "\n",
    "Time complexity = O(b^d)  \n",
    "Space complexity = O(bd)  \n",
    "As for the best case, space complexity = O(b^(d/2)) (AlphaBeta Cut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59dcf9",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75f727f",
   "metadata": {},
   "source": [
    "**To start off, we're going to use Graphical User-Interface as an output method.**  \n",
    "And these are some constant variables in which we are going to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbff4e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PIXELS ---\n",
    "\n",
    "WIDTH = 600\n",
    "HEIGHT = 600\n",
    "\n",
    "# --- SIZE ---\n",
    "\n",
    "ROWS = 3\n",
    "COLS = 3\n",
    "SQSIZE = WIDTH // COLS\n",
    "\n",
    "# --- COMPONANT'S SIZE ---\n",
    "\n",
    "LINE_WIDTH = 10\n",
    "CIRC_WIDTH = 15\n",
    "CROSS_WIDTH = 20\n",
    "RADIUS = SQSIZE / 2.5\n",
    "OFFSET = 30\n",
    "\n",
    "# --- COLORS ---\n",
    "\n",
    "BG_COLOR = (255, 255, 255)\n",
    "LINE_COLOR = (200, 170, 0)\n",
    "CIRC_COLOR = (255, 0, 0)\n",
    "CROSS_COLOR = (0, 106, 0)\n",
    "WINNING_COLOR = (255,255,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95718010",
   "metadata": {},
   "source": [
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7fa846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import sys\n",
    "import pygame\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e911d30f",
   "metadata": {},
   "source": [
    "**Now, we have created multiple classes with different purposess**  \n",
    "We'll discuss the code in details in comment format i.e (# vertical wins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f773f50",
   "metadata": {},
   "source": [
    "First class is the **Board** class.  \n",
    "Which deals with the implementation of the board it self. And decides who wins or if it's a tie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ddad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Board:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.squares = np.zeros( (ROWS, COLS) )\n",
    "        self.empty_sqrs = self.squares # [squares]\n",
    "        self.marked_sqrs = 0\n",
    "\n",
    "    def final_state(self, show=False):\n",
    "        '''\n",
    "            @return 0 if there is no win yet\n",
    "            @return 1 if player 1 wins\n",
    "            @return 2 if player 2 wins\n",
    "        '''\n",
    "\n",
    "        # vertical wins\n",
    "        for col in range(COLS):\n",
    "            if self.squares[0][col] == self.squares[1][col] == self.squares[2][col] != 0:\n",
    "                if show:\n",
    "                    color = WINNING_COLOR if self.squares[0][col] == 2 else WINNING_COLOR\n",
    "                    iPos = (col * SQSIZE + SQSIZE // 2, 20)\n",
    "                    fPos = (col * SQSIZE + SQSIZE // 2, HEIGHT - 20)\n",
    "                    pygame.draw.line(screen, color, iPos, fPos, LINE_WIDTH)\n",
    "                return self.squares[0][col]\n",
    "\n",
    "        # horizontal wins\n",
    "        for row in range(ROWS):\n",
    "            if self.squares[row][0] == self.squares[row][1] == self.squares[row][2] != 0:\n",
    "                if show:\n",
    "                    color = WINNING_COLOR if self.squares[row][0] == 2 else WINNING_COLOR\n",
    "                    iPos = (20, row * SQSIZE + SQSIZE // 2)\n",
    "                    fPos = (WIDTH - 20, row * SQSIZE + SQSIZE // 2)\n",
    "                    pygame.draw.line(screen, color, iPos, fPos, LINE_WIDTH)\n",
    "                return self.squares[row][0]\n",
    "\n",
    "        # desc diagonal\n",
    "        if self.squares[0][0] == self.squares[1][1] == self.squares[2][2] != 0:\n",
    "            if show:\n",
    "                color = WINNING_COLOR if self.squares[1][1] == 2 else WINNING_COLOR\n",
    "                iPos = (20, 20)\n",
    "                fPos = (WIDTH - 20, HEIGHT - 20)\n",
    "                pygame.draw.line(screen, color, iPos, fPos, CROSS_WIDTH)\n",
    "            return self.squares[1][1]\n",
    "\n",
    "        # asc diagonal\n",
    "        if self.squares[2][0] == self.squares[1][1] == self.squares[0][2] != 0:\n",
    "            if show:\n",
    "                color = WINNING_COLOR if self.squares[1][1] == 2 else WINNING_COLOR\n",
    "                iPos = (20, HEIGHT - 20)\n",
    "                fPos = (WIDTH - 20, 20)\n",
    "                pygame.draw.line(screen, color, iPos, fPos, CROSS_WIDTH)\n",
    "            return self.squares[1][1]\n",
    "\n",
    "        # no win yet\n",
    "        return 0\n",
    "\n",
    "    def mark_sqr(self, row, col, player):\n",
    "        self.squares[row][col] = player\n",
    "        self.marked_sqrs += 1\n",
    "\n",
    "    def empty_sqr(self, row, col):\n",
    "        return self.squares[row][col] == 0\n",
    "\n",
    "    def get_empty_sqrs(self):\n",
    "        empty_sqrs = []\n",
    "        for row in range(ROWS):\n",
    "            for col in range(COLS):\n",
    "                if self.empty_sqr(row, col):\n",
    "                    empty_sqrs.append( (row, col) )\n",
    "        \n",
    "        return empty_sqrs\n",
    "\n",
    "    def isfull(self):\n",
    "        return self.marked_sqrs == 9\n",
    "\n",
    "    def isempty(self):\n",
    "        return self.marked_sqrs == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2752fb",
   "metadata": {},
   "source": [
    "The second class is the **AI** class.  \n",
    "Which will be dealing with the most important aspect of the tutorial.  \n",
    "**MinMax** and **Alpha-Beta Pruning** implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f9ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI:\n",
    "    \n",
    "    \n",
    "\n",
    "    def __init__(self, level=1, player=2):\n",
    "        self.level = level# Level 1 is for alpha-beta, 2 is for minmax.\n",
    "        self.player = player\n",
    "\n",
    "        # --- ALPHA-BETA ---\n",
    "        \n",
    "    def alphaBeta(self, board, depth, alpha, beta, maximizing):\n",
    "        global treesize\n",
    "        treesize += 1\n",
    "        # terminal case\n",
    "        \n",
    "        case = board.final_state()\n",
    "        \n",
    "        if depth == 0:\n",
    "            return case, None\n",
    "            \n",
    "        # player 1 wins\n",
    "        if case == 1:\n",
    "            return 1, None # eval, move\n",
    "\n",
    "        # player 2 wins\n",
    "        if case == 2:\n",
    "            return -1, None\n",
    "\n",
    "        # draw\n",
    "        elif board.isfull():\n",
    "            return 0, None\n",
    "\n",
    "        if maximizing:\n",
    "            max_eval = -100\n",
    "            best_move = None\n",
    "            empty_sqrs = board.get_empty_sqrs()\n",
    "\n",
    "            for (row, col) in empty_sqrs:\n",
    "                temp_board = copy.deepcopy(board)\n",
    "                temp_board.mark_sqr(row, col, 1)\n",
    "                eval = self.alphaBeta(temp_board,depth-1,alpha,beta, False)[0]\n",
    "                if eval > max_eval:\n",
    "                    max_eval = eval\n",
    "                    best_move = (row, col)\n",
    "                    alpha = max(alpha, max_eval)#AlphaBetaCut\n",
    "                    if beta<=alpha:\n",
    "                        break\n",
    "            return max_eval, best_move\n",
    "\n",
    "        elif not maximizing:\n",
    "            min_eval = 100\n",
    "            best_move = None\n",
    "            empty_sqrs = board.get_empty_sqrs()\n",
    "\n",
    "            for (row, col) in empty_sqrs:\n",
    "                temp_board = copy.deepcopy(board)\n",
    "                temp_board.mark_sqr(row, col, self.player)\n",
    "                eval = self.alphaBeta(temp_board,depth-1,alpha,beta, True)[0]\n",
    "                if eval < min_eval:\n",
    "                    min_eval = eval\n",
    "                    best_move = (row, col)\n",
    "                    beta = min(beta, min_eval)#AlphaBetaCut\n",
    "                    if beta <= alpha:\n",
    "                        break\n",
    "                    \n",
    "                    \n",
    "            return min_eval, best_move\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    # --- MINIMAX ---\n",
    "\n",
    "    def minimax(self, board, depth, maximizing):\n",
    "        \n",
    "        global treesize\n",
    "        treesize = treesize + 1\n",
    "        # terminal case\n",
    "        \n",
    "        case = board.final_state()\n",
    "        \n",
    "        if depth == 0:\n",
    "            return case, None\n",
    "            \n",
    "        # player 1 wins\n",
    "        if case == 1:\n",
    "            return 1, None # eval, move\n",
    "\n",
    "        # player 2 wins\n",
    "        if case == 2:\n",
    "            return -1, None\n",
    "\n",
    "        # draw\n",
    "        elif board.isfull():\n",
    "            return 0, None\n",
    "\n",
    "        if maximizing:\n",
    "            max_eval = -100\n",
    "            best_move = None\n",
    "            empty_sqrs = board.get_empty_sqrs()\n",
    "\n",
    "            for (row, col) in empty_sqrs:\n",
    "                temp_board = copy.deepcopy(board)\n",
    "                temp_board.mark_sqr(row, col, 1)\n",
    "                eval = self.minimax(temp_board,depth-1, False)[0]\n",
    "                if eval > max_eval:\n",
    "                    max_eval = eval\n",
    "                    best_move = (row, col)\n",
    "                    \n",
    "            return max_eval, best_move\n",
    "\n",
    "        elif not maximizing:\n",
    "            min_eval = 100\n",
    "            best_move = None\n",
    "            empty_sqrs = board.get_empty_sqrs()\n",
    "\n",
    "            for (row, col) in empty_sqrs:\n",
    "                temp_board = copy.deepcopy(board)\n",
    "                temp_board.mark_sqr(row, col, self.player)\n",
    "                eval = self.minimax(temp_board,depth-1, True)[0]\n",
    "                if eval < min_eval:\n",
    "                    min_eval = eval\n",
    "                    best_move = (row, col)\n",
    "\n",
    "            return min_eval, best_move\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "    # --- MAIN EVAL ---\n",
    "\n",
    "    def eval(self, main_board):\n",
    "      \n",
    "        \n",
    "        \n",
    "        if self.level == 0:\n",
    "         # alpha-beta algo choice\n",
    "         start = time.time()#Start of the timer.\n",
    "         eval, move = self.alphaBeta(main_board, 9, -1000, 1000, False)\n",
    "         end = time.time()#End of the timer.\n",
    "         \n",
    "        else:\n",
    "            # minimax algo choice\n",
    "            start = time.time()#Start of the timer.\n",
    "            eval, move = self.minimax(main_board, 9, False)\n",
    "            end = time.time()#End of the timer.\n",
    "            \n",
    "        timer = (end-start)#Calculate total time taken.\n",
    "        print(f'AI has chosen to mark the square in pos {move} with an eval of: {eval}')\n",
    "        print(treesize)  \n",
    "        print(round(timer, 5))\n",
    "        \n",
    "         \n",
    "        return move # row, col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca13546",
   "metadata": {},
   "source": [
    "Our final class, the **Game** class.  \n",
    "It is responsible for making the moves for each player, drawing the winning lines and resetting the game, more on it in the code it self.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "300d8f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.board = Board()\n",
    "        self.ai = AI()\n",
    "        self.player = 1 #1-cross  #2-circles.\n",
    "        self.gamemode = 'ai' # pvp or ai.\n",
    "        self.running = True # When False = Either some one won or it's a draw.\n",
    "        self.show_lines()\n",
    "        global treesize\n",
    "        treesize = 0\n",
    "\n",
    "    # --- DRAW METHODS ---\n",
    "\n",
    "    def show_lines(self):\n",
    "        # bg\n",
    "        screen.fill( BG_COLOR )\n",
    "\n",
    "        # vertical\n",
    "        pygame.draw.line(screen, LINE_COLOR, (SQSIZE, 0), (SQSIZE, HEIGHT), LINE_WIDTH)\n",
    "        pygame.draw.line(screen, LINE_COLOR, (WIDTH - SQSIZE, 0), (WIDTH - SQSIZE, HEIGHT), LINE_WIDTH)\n",
    "\n",
    "        # horizontal\n",
    "        pygame.draw.line(screen, LINE_COLOR, (0, SQSIZE), (WIDTH, SQSIZE), LINE_WIDTH)\n",
    "        pygame.draw.line(screen, LINE_COLOR, (0, HEIGHT - SQSIZE), (WIDTH, HEIGHT - SQSIZE), LINE_WIDTH)\n",
    "\n",
    "    def draw_fig(self, row, col):\n",
    "        if self.player == 1:\n",
    "            # draw cross\n",
    "            # desc line\n",
    "            start_desc = (col * SQSIZE + OFFSET, row * SQSIZE + OFFSET)\n",
    "            end_desc = (col * SQSIZE + SQSIZE - OFFSET, row * SQSIZE + SQSIZE - OFFSET)\n",
    "            pygame.draw.line(screen, CROSS_COLOR, start_desc, end_desc, CROSS_WIDTH)\n",
    "            # asc line\n",
    "            start_asc = (col * SQSIZE + OFFSET, row * SQSIZE + SQSIZE - OFFSET)\n",
    "            end_asc = (col * SQSIZE + SQSIZE - OFFSET, row * SQSIZE + OFFSET)\n",
    "            pygame.draw.line(screen, CROSS_COLOR, start_asc, end_asc, CROSS_WIDTH)\n",
    "        \n",
    "        elif self.player == 2:\n",
    "            # draw circle\n",
    "            center = (col * SQSIZE + SQSIZE // 2, row * SQSIZE + SQSIZE // 2)\n",
    "            pygame.draw.circle(screen, CIRC_COLOR, center, RADIUS, CIRC_WIDTH)\n",
    "\n",
    "    # --- OTHER METHODS ---\n",
    "    \n",
    "    def make_move(self, row, col):\n",
    "        self.board.mark_sqr(row, col, self.player)\n",
    "        self.draw_fig(row, col)\n",
    "        self.next_turn()\n",
    "\n",
    "    def next_turn(self):\n",
    "        self.player = self.player % 2 + 1\n",
    "\n",
    "    def change_gamemode(self):\n",
    "        self.gamemode = 'ai' if self.gamemode == 'pvp' else 'pvp'\n",
    "\n",
    "    def isover(self):\n",
    "        return self.board.final_state(show=True) != 0 or self.board.isfull()\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495717dd",
   "metadata": {},
   "source": [
    "**Main method and pygame setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "770e8ac0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- PYGAME-SETUP ---\n",
    "pygame.init()\n",
    "screen = pygame.display.set_mode( (WIDTH, HEIGHT) )\n",
    "pygame.display.set_caption('TIC TAC TOE AI')\n",
    "screen.fill( BG_COLOR )\n",
    "\n",
    "# --- MAIN-METHOD ---\n",
    "def main():\n",
    "\n",
    "    # --- OBJECTS ---\n",
    "\n",
    "    game = Game()\n",
    "    board = game.board\n",
    "    ai = game.ai\n",
    "\n",
    "    # --- MAINLOOP ---\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        # pygame events\n",
    "        for event in pygame.event.get():\n",
    "\n",
    "            # quit event\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                sys.exit()\n",
    "\n",
    "            # keydown event\n",
    "            if event.type == pygame.KEYDOWN:\n",
    "\n",
    "                # g-gamemode\n",
    "                if event.key == pygame.K_g:\n",
    "                    game.change_gamemode()\n",
    "\n",
    "                # r-restart\n",
    "                if event.key == pygame.K_r:\n",
    "                    game.reset()\n",
    "                    board = game.board\n",
    "                    \n",
    "                    \n",
    "               # 0-AlphaBeta    \n",
    "                if event.key == pygame.K_0:\n",
    "                    ai.level = 0 \n",
    "                 \n",
    "                    \n",
    "               # 1-MinMax\n",
    "                if event.key == pygame.K_1:\n",
    "                    ai.level = 1\n",
    "\n",
    "            # click event\n",
    "            if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                pos = event.pos\n",
    "                row = pos[1] // SQSIZE\n",
    "                col = pos[0] // SQSIZE\n",
    "                \n",
    "                # human mark sqr\n",
    "                if board.empty_sqr(row, col) and game.running:\n",
    "                    game.make_move(row, col)\n",
    "\n",
    "                    if game.isover():\n",
    "                        game.running = False\n",
    "\n",
    "\n",
    "        # AI initial call\n",
    "        if game.gamemode == 'ai' and game.player == ai.player and game.running:\n",
    "\n",
    "            # update the screen\n",
    "            pygame.display.update()\n",
    "\n",
    "            # eval\n",
    "            row, col = ai.eval(board)\n",
    "            game.make_move(row, col)\n",
    "\n",
    "            if game.isover():\n",
    "                game.running = False\n",
    "            \n",
    "        pygame.display.update()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0bf59d",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81bae0",
   "metadata": {},
   "source": [
    "We've tested the two algorithms 10 times each on different depth, and calculated the time the AI takes to find a solution, the final tree size, and the score of the match.  \n",
    "we made 3 runs at depth = 2  \n",
    "3 runs at depth = 5  \n",
    "3 runs at depth = 7  \n",
    "1 run at depth = 9 (the whole game tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7472fd5",
   "metadata": {},
   "source": [
    "For the **MinMax Algorithm:**    \n",
    "**Depth** = 2  \n",
    " **run1**   \n",
    "tie, tree size = 124 time = 0.004s  \n",
    " **run2**   \n",
    "win, tree size = 124 time = 0.006s  \n",
    " **run3**  \n",
    "loss, tree size = 116  time = 0.003s  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2fd494",
   "metadata": {},
   "source": [
    "**Depth** = 5  \n",
    " **run1**   \n",
    "win, tree size = 8854 total time = 0.15021s  \n",
    " **run2**    \n",
    "loss, tree size = 9034 total time = 0.15189s  \n",
    " **run3**   \n",
    "loss, tree size = 8569 time = 0.14941s  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5c58a",
   "metadata": {},
   "source": [
    "**Depth** = 7  \n",
    " **run1**    \n",
    "tie, tree size = 64730 time = 0.74s  \n",
    " **run2**   \n",
    "loss, tree size = 64723 time = 0.78191s  \n",
    " **run3**   \n",
    "tie, tree size = 43142 time = 0.6731s  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa6df49",
   "metadata": {},
   "source": [
    "**Depth** = 9  \n",
    " **run**  \n",
    "tie, tree size = 60698 time = 1.097s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3367786e",
   "metadata": {},
   "source": [
    "Number of wins   = 2  \n",
    "Number of losses = 4  \n",
    "Number of ties   = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d3e9f",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18057fd8",
   "metadata": {},
   "source": [
    "For the **Alpha-Beta Prunning:**   \n",
    "**Depth** = 2  \n",
    "**run1**  \n",
    "win, tree size = 63 time = 0.002s  \n",
    "**run2**  \n",
    "loss, tree size = 58 time = 0.001s  \n",
    "**run3**  \n",
    "win, tree size = 68 time = 0.002s  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fdb324",
   "metadata": {},
   "source": [
    "**Depth** = 5  \n",
    "**run1**  \n",
    "win, tree size = 653 total time = 0.0199s  \n",
    "**run2**  \n",
    "tie, tree size = 664 total time = 0.0202s  \n",
    "**run3**  \n",
    "win, tree size = 666 time = 0.012s  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daef0cda",
   "metadata": {},
   "source": [
    "**Depth** = 7    \n",
    "**run1**    \n",
    "tie, tree size = 1992 time = 0.0361s  \n",
    "**run2**    \n",
    "loss, tree size = 2753 time = 0.0549s  \n",
    "**run3**    \n",
    "tie, tree size = 3323 time = 0.0595s  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceeeaca",
   "metadata": {},
   "source": [
    "**Depth** = 9  \n",
    "**run**   \n",
    "tie, tree size = 4036 time = 0.0768s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0afad8c",
   "metadata": {},
   "source": [
    "Number of wins   = 4  \n",
    "Number of losses = 2  \n",
    "Number of ties = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08655491",
   "metadata": {},
   "source": [
    "![SegmentLocal](testing.png \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc480ee3",
   "metadata": {},
   "source": [
    "So in the end, there's not much of a difference in terms of the two algorithms and how they behave(choosing which path or solution). However the time needed to reach a solution differs. \n",
    "As mentioned above, the time complexity for **AlphaBeta** is O(b^(d/2)) for the best case and the same as **MinMax** for the worst."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
